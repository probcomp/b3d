{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import imageio\n",
    "from b3d.io.feature_track_data import FeatureTrackData\n",
    "from b3d.io.segmented_video_input import SegmentedVideoInput\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_label(img, label):\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = img.shape[0] / 400\n",
    "    thickness = img.shape[0] // 200\n",
    "    label_height = img.shape[0] // 10\n",
    "    label_position = img.shape[0] // 14\n",
    "    color = (255, 255, 255)\n",
    "    img = cv2.copyMakeBorder(img, label_height, 0, 0, 0, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "    cv2.putText(img, label, (10, label_position), font, font_scale, color, thickness, cv2.LINE_AA)\n",
    "    return img\n",
    "\n",
    "def resize_img(img, downscale):\n",
    "    return cv2.resize(img, (0, 0), fx=downscale, fy=downscale)\n",
    "\n",
    "def create_color_map(segmentation):\n",
    "    unique_ids = np.unique(segmentation)\n",
    "    color_map = np.zeros((unique_ids.max() + 1, 3), dtype=np.uint8)\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    for uid in unique_ids:\n",
    "        color_map[uid] = np.random.randint(0, 255, 3)\n",
    "    \n",
    "    return color_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rgb_image(rgb, label=None):\n",
    "    if data.rgb.dtype == np.uint8:\n",
    "        rgb_img = np.array(rgb, dtype=np.uint8)\n",
    "    elif data.rgb.dtype == np.float32:\n",
    "        rgb_img = np.array(rgb * 255, dtype=np.uint8)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported RGB data type\")\n",
    "    \n",
    "    if label:\n",
    "        rgb_img = add_label(rgb_img, label)\n",
    "    return rgb_img.astype(np.uint8)\n",
    "\n",
    "def create_depth_image(depth_float, label=None):\n",
    "    depth_img = np.array(depth_float, dtype=float)\n",
    "    depth_img = cv2.normalize(depth_img, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    depth_img = cv2.applyColorMap(depth_img.astype(np.uint8), cv2.COLORMAP_JET)\n",
    "    if label:        \n",
    "        depth_img = add_label(depth_img, label)\n",
    "    return depth_img.astype(np.uint8)\n",
    "\n",
    "def create_keypoints_image(visible_keypoints, W, H, label=None):\n",
    "    keypoints_img = np.zeros((H, W, 3), dtype=np.uint8)\n",
    "    for kp in visible_keypoints:\n",
    "        cv2.circle(keypoints_img, (int(kp[0]), int(kp[1])), 1, (0, 255, 0), -1)\n",
    "    if label:\n",
    "        keypoints_img = add_label(keypoints_img, label)\n",
    "    return keypoints_img.astype(np.uint8)\n",
    "\n",
    "def create_segmentation_image(segmentation_int, color_map, label=None):\n",
    "    segmentation_img = color_map[segmentation_int].astype(np.uint8)\n",
    "    if label:        \n",
    "        segmentation_img = add_label(segmentation_img, label)\n",
    "    return segmentation_img.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_track_frame(rgb, depth, visible_keypoints, width=None, height=None):\n",
    "    if width is None:\n",
    "        width = int(rgb.shape[1])\n",
    "    if height is None:\n",
    "        height = int(rgb.shape[0])\n",
    "    rgb_img = create_rgb_image(rgb, 'RGB')\n",
    "    depth_img = create_depth_image(depth, 'Depth')\n",
    "    keypoints_img = create_keypoints_image(visible_keypoints, width, height, 'Visible Keypoints')\n",
    "    img = np.hstack((rgb_img, depth_img, keypoints_img))\n",
    "    return img.astype(np.uint8)\n",
    "\n",
    "def create_segmented_video_input_frame(rgb, depth, segmentation, color_map):\n",
    "    rgb_img = create_rgb_image(rgb, 'RGB')\n",
    "    depth_img = create_depth_image(depth, 'Depth')\n",
    "    segmentation_img = create_segmentation_image(segmentation, color_map, 'Segmentation')\n",
    "    img = np.hstack((rgb_img, depth_img, segmentation_img))\n",
    "    return img.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_video(img_array, create_image_function, output_path='output.gif', label=None, res=None, fps=10, slow=1, source_fps=30):\n",
    "    Nframe = img_array.shape[0]\n",
    "    frames = []\n",
    "\n",
    "    width = img_array.shape[2]\n",
    "    resize_factor = 1\n",
    "    if (res):\n",
    "        resize_factor = float(res / width)\n",
    "    frame_step = int(source_fps / fps)\n",
    "\n",
    "    for t in range(0, Nframe, frame_step):  # Skip every \"frame_step\"\n",
    "        frame = create_image_function(img_array[t], label=label)\n",
    "        frame = resize_img(frame, resize_factor) \n",
    "        frames.append(frame)\n",
    "\n",
    "    imageio.mimsave(output_path, frames, fps=slow * fps)\n",
    "    print(f\"Saved {output_path}\")\n",
    "\n",
    "def create_keypoints_video(keypoints_positions, visibility_mask, width, height, output_path='output.gif', label=None, res=None, fps=10, slow=1, source_fps=30):\n",
    "    Nframe = keypoints_positions.shape[0]\n",
    "    frames = []\n",
    "\n",
    "    resize_factor = 1\n",
    "    if (res):\n",
    "        resize_factor = float(res / width)\n",
    "    frame_step = int(source_fps / fps)\n",
    "\n",
    "    for t in range(0, Nframe, frame_step):  # Skip every \"frame_step\"\n",
    "        visible_keypoints = keypoints_positions[t][visibility_mask[t]]\n",
    "        frame = create_keypoints_image(visible_keypoints, width, height, label=label)\n",
    "        frame = resize_img(frame, resize_factor) \n",
    "        frames.append(frame)\n",
    "    imageio.mimsave(output_path, frames, fps=slow * fps)\n",
    "    print(f\"Saved {output_path}\")\n",
    "\n",
    "def create_segmentation_video(img_array, output_path='output.gif', res=None, fps=10, slow=1, source_fps=30, label=None):\n",
    "    Nframe = img_array.shape[0]\n",
    "    frames = []\n",
    "\n",
    "    width = img_array.shape[2]\n",
    "    resize_factor = 1\n",
    "    if (res):\n",
    "        resize_factor = float(res / width)\n",
    "    frame_step = int(source_fps / fps)\n",
    "    \n",
    "    color_map = create_color_map(img_array)\n",
    "\n",
    "    for t in range(0, Nframe, frame_step):  # Skip every \"frame_step\"\n",
    "        frame = create_segmentation_image(img_array[t], color_map=color_map, label=label)\n",
    "        frame = resize_img(frame, resize_factor) \n",
    "        frames.append(frame)\n",
    "\n",
    "    imageio.mimsave(output_path, frames, fps=slow * fps)\n",
    "    print(f\"Saved {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/home/tiffa/b3d/assets/large_data_bucket/unity/toyroom/ballstriking/feature_track_data/lit_bg_200p.input.npz'\n",
    "\n",
    "data = FeatureTrackData.load(filepath)\n",
    "\n",
    "W = int(data.camera_intrinsics[0])\n",
    "H = int(data.camera_intrinsics[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_track_video(data: FeatureTrackData, output_path='output.gif', res=None, fps=10, slow=1, source_fps=30):\n",
    "    Nframe = data.rgbd_images.shape[0]\n",
    "    width = data.rgbd_images.shape[2]\n",
    "    height = data.rgbd_images.shape[1]\n",
    "    \n",
    "    resize_factor = 1\n",
    "    if (res):\n",
    "        resize_factor = float(res / width)\n",
    "\n",
    "    frames = []\n",
    "    frame_step = int(source_fps / fps)\n",
    "    for t in range(0, Nframe, frame_step):  # Skip every \"frame_step\"\n",
    "        rgb = data.rgbd_images[t, :, :, :3] \n",
    "        depth = data.rgbd_images[t, :, :, 3] \n",
    "        kp = data.observed_keypoints_positions[t][data.keypoint_visibility[t]]\n",
    "        frame = create_feature_track_frame(rgb, depth, kp, width, height)\n",
    "        frame = resize_img(frame, resize_factor) \n",
    "        frames.append(frame)\n",
    "    imageio.mimsave(output_path, frames, fps=slow * fps)\n",
    "    print(f\"Saved {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved output.mp4\n"
     ]
    }
   ],
   "source": [
    "create_feature_track_video(data, output_path='output.mp4', res=800, fps=10, slow=1, source_fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t=0\n",
    "# rgb = data.rgbd_images[t, :, :, :3] \n",
    "# rgb_img = create_rgb_image(rgb, 'RGB')\n",
    "\n",
    "# depth = data.rgbd_images[t, :, :, 3] \n",
    "# depth_img = create_depth_image(depth, 'Depth')\n",
    "\n",
    "# kp = data.observed_keypoints_positions[t][data.keypoint_visibility[t]]\n",
    "# kp_img = create_keypoints_image(kp, W, H, 'Visible Keypoints')\n",
    "# # kp_img = resize_img(kp_img, 4)\n",
    "\n",
    "# combined_img = create_feature_track_frame(rgb, depth, kp)\n",
    "# combined_img = resize_img(combined_img, 4)\n",
    "\n",
    "# plt.imshow(combined_img)\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rgb_array = data.rgbd_images[:, :, :, :3] \n",
    "# depth_array = data.rgbd_images[:, :, :, 3] \n",
    "\n",
    "# # create_video(rgb_array, create_rgb_image, output_path='output.gif', fps=10, slow=1, source_fps=data.fps, res=100, label=None)\n",
    "# # create_gif(depth_array, create_depth_image, output_path='output.gif', fps=10, slow=1, source_fps=data.fps, res=100, label=None)\n",
    "\n",
    "# create_keypoints_video(data.observed_keypoints_positions, data.keypoint_visibility, W, H, output_path='output.mp4', fps=10, slow=1, source_fps=data.fps, res=200, label=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/home/tiffa/b3d/assets/large_data_bucket/unity/toyroom/blockmostlyoccluded/segmented_video_input/lit_bg_800p.input.npz'\n",
    "\n",
    "data = SegmentedVideoInput.load(filepath)\n",
    "\n",
    "W = int(data.camera_intrinsics_rgb[0])\n",
    "H = int(data.camera_intrinsics_rgb[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_segmented_video_input_video(data: SegmentedVideoInput, output_path='output.gif', res=None, fps=10, slow=1, source_fps=30):\n",
    "    Nframe = data.rgb.shape[0]\n",
    "\n",
    "    width = data.rgb.shape[1]\n",
    "    resize_factor = 1\n",
    "    if (res):\n",
    "        resize_factor = float(res / width)\n",
    "    \n",
    "    color_map = create_color_map(data.segmentation)\n",
    "\n",
    "    frames = []\n",
    "    frame_step = int(source_fps / fps)\n",
    "    for t in range(0, Nframe, frame_step):  # Skip every \"frame_step\"\n",
    "        rgb = data.rgb[t, :, :, :3]\n",
    "        \n",
    "        # Compute depth image from XYZ positions\n",
    "        xyz = data.xyz[t]\n",
    "        depth = xyz[..., 2]  # Z is the depth\n",
    "        segmentation = data.segmentation[t]\n",
    "        frame = create_segmented_video_input_frame(rgb, depth, segmentation, color_map)\n",
    "        frame = resize_img(frame, resize_factor) \n",
    "        frames.append(frame)\n",
    "    imageio.mimsave(output_path, frames, fps=slow * fps)\n",
    "    print(f\"Saved {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/b3d/lib/python3.12/subprocess.py:1885: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = _fork_exec(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved output.mp4\n"
     ]
    }
   ],
   "source": [
    "create_segmented_video_input_video(data, output_path='output.mp4', res=800, fps=10, slow=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "b3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
