{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import trimesh\n",
    "import b3d\n",
    "import genjax\n",
    "import jax\n",
    "import b3d.bayes3d as bayes3d\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import rerun as rr\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import json\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import itertools\n",
    "import pycocotools.mask as mask_util\n",
    "from scipy.spatial.transform import Rotation\n",
    "from tqdm import tqdm\n",
    "from functools import reduce\n",
    "from genjax import Pytree\n",
    "from physion_utils import *\n",
    "import b3d.chisight.dense.dense_model\n",
    "import b3d.chisight.dense.likelihoods.laplace_likelihood\n",
    "import collections\n",
    "from genjax._src.core.serialization.msgpack import msgpack_serialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.init(\"demo\")\n",
    "rr.connect(\"127.0.0.1:8812\")\n",
    "rr.log(\"/\", rr.ViewCoordinates.LEFT_HAND_Y_UP, static=True)  # Set an up-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths for reading physion metadata\n",
    "physion_assets_path = os.path.join(\n",
    "    b3d.get_root_path(),\n",
    "    \"assets/physion/\",)\n",
    "\n",
    "resnet_inference_path = os.path.join(\n",
    "    b3d.get_root_path(),\n",
    "    \"resnet_results/\",)\n",
    "\n",
    "stim_name = 'pilot_dominoes_0mid_d3chairs_o1plants_tdwroom_0001'\n",
    "\n",
    "hdf5_file_path = os.path.join(physion_assets_path,\n",
    "    f\"{stim_name}.hdf5\",\n",
    ")\n",
    "\n",
    "mesh_file_path = os.path.join(physion_assets_path,\n",
    "    f\"all_flex_meshes/core\",\n",
    ")\n",
    "\n",
    "json_file_path = os.path.join(resnet_inference_path,\n",
    "    f\"{stim_name}.json\",\n",
    ")\n",
    "\n",
    "im_width = 350\n",
    "im_height = 350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vfov = 54.43222 \n",
    "near_plane = 0.1\n",
    "far_plane = 100\n",
    "depth_arr = []\n",
    "image_arr = []\n",
    "base_id, base_type, attachment_id, attachent_type, attachment_fixed, use_attachment, use_base, use_cap = None, None, None, None, None, None, None, None\n",
    "with h5py.File(hdf5_file_path, \"r\") as f:\n",
    "    # extract depth info\n",
    "    for key in f['frames'].keys():\n",
    "        depth = jnp.array(Image.fromarray(np.array(f['frames'][key]['images']['_depth_cam0'])).resize((im_width, im_height), Image.BICUBIC))\n",
    "        depth_arr.append(depth)\n",
    "        image = jnp.array(Image.open(io.BytesIO(f['frames'][key]['images']['_img_cam0'][:])).resize((im_width, im_height), Image.BICUBIC))\n",
    "        image_arr.append(image)\n",
    "    depth_arr = jnp.asarray(depth_arr)\n",
    "    image_arr = jnp.asarray(image_arr)/255\n",
    "    FINAL_T, height, width = image_arr.shape[0], image_arr.shape[1], image_arr.shape[2]\n",
    "\n",
    "    # extract camera info\n",
    "    camera_azimuth = np.array(f['azimuth']['cam_0'])\n",
    "    camera_matrix = np.array(f['frames']['0000']['camera_matrices']['camera_matrix_cam0']).reshape((4, 4))\n",
    "    projection_matrix = np.array(f['frames']['0000']['camera_matrices']['projection_matrix_cam0']).reshape((4, 4))\n",
    "    im_seg = np.array(Image.open(io.BytesIO(f['frames']['0000']['images']['_id_cam0'][:])).resize((im_width, im_height), Image.BICUBIC))\n",
    "\n",
    "    # Calculate the intrinsic matrix from vertical_fov.\n",
    "    # Motice that hfov and vfov are different if height != width\n",
    "    # We can also get the intrinsic matrix from opengl's perspective matrix.\n",
    "    # http://kgeorge.github.io/2014/03/08/calculating-opengl-perspective-matrix-from-opencv-intrinsic-matrix\n",
    "    vfov = vfov / 180.0 * np.pi\n",
    "    tan_half_vfov = np.tan(vfov / 2.0)\n",
    "    tan_half_hfov = tan_half_vfov * width / float(height)\n",
    "    fx = width / 2.0 / tan_half_hfov  # focal length in pixel space\n",
    "    fy = height / 2.0 / tan_half_vfov\n",
    "\n",
    "    # extract object info\n",
    "    object_ids = np.array(f['static']['object_ids'])\n",
    "    model_names = np.array(f['static']['model_names'])\n",
    "    assert len(object_ids) == len(model_names)\n",
    "\n",
    "    distractors = np.array(f['static']['distractors']) if np.array(f['static']['distractors']).size != 0 else None\n",
    "    occluders = np.array(f['static']['occluders']) if np.array(f['static']['occluders']).size != 0 else None\n",
    "    distractor_ids = np.concatenate([np.where(model_names==distractor)[0] for distractor in distractors], axis=0).tolist() if distractors else []\n",
    "    occluder_ids = np.concatenate([np.where(model_names==occluder)[0] for occluder in occluders], axis=0).tolist() if occluders else []\n",
    "    excluded_model_ids = distractor_ids+occluder_ids\n",
    "    included_model_ids = [idx for idx in range(len(object_ids)) if idx not in excluded_model_ids]\n",
    "    object_ids = included_model_ids\n",
    "    \n",
    "    object_segmentation_colors = np.array(f['static']['object_segmentation_colors'])\n",
    "    initial_position = np.array(f['static']['initial_position'])\n",
    "    initial_rotation = np.array(f['static']['initial_rotation'])\n",
    "    scales = np.array(f['static']['scale'])\n",
    "    if \"base_id\" in np.array(f['static']) and \"attachment_id\" in np.array(f['static']):\n",
    "        base_id = np.array(f['static']['base_id'])\n",
    "        base_type = np.array(f['static']['base_type'])\n",
    "        attachment_id = np.array(f['static']['attachment_id'])\n",
    "        attachent_type = np.array(f['static']['attachent_type'])\n",
    "        attachment_fixed = np.array(f['static']['attachment_fixed'])\n",
    "        use_attachment = np.array(f['static']['use_attachment'])\n",
    "        use_base = np.array(f['static']['use_base'])\n",
    "        use_cap = np.array(f['static']['use_cap'])\n",
    "        assert attachment_id.size==1\n",
    "        assert base_id.size==1\n",
    "        attachment_id = attachment_id.item()\n",
    "        base_id = base_id.item()\n",
    "        print(base_id, base_type, attachment_id, attachent_type, attachment_fixed, use_attachment, use_base, use_cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_meshes = {}\n",
    "for path, dirs, files in os.walk(mesh_file_path):\n",
    "    for name in (files + dirs):\n",
    "        if name.endswith('.obj'):\n",
    "            mesh = trimesh.load(os.path.join(path, name))\n",
    "            all_meshes[name[:-4]] = mesh\n",
    "ordered_all_meshes = collections.OrderedDict(sorted(all_meshes.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haoliangwang/b3d/.pixi/envs/gpu/lib/python3.12/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Defines the enumeration schedule.\n",
    "scaling_factor = 1.0\n",
    "renderer = b3d.renderer.renderer_original.RendererOriginal(\n",
    "    width * scaling_factor,\n",
    "    height * scaling_factor,\n",
    "    fx * scaling_factor,\n",
    "    fy * scaling_factor,\n",
    "    (width/2) * scaling_factor,\n",
    "    (height/2) * scaling_factor,\n",
    "    near_plane,\n",
    "    far_plane,\n",
    ")\n",
    "\n",
    "b3d.reload(b3d.chisight.dense.dense_model)\n",
    "b3d.reload(b3d.chisight.dense.likelihoods.laplace_likelihood)\n",
    "likelihood_func = b3d.chisight.dense.likelihoods.laplace_likelihood.likelihood_func\n",
    "model, viz_trace, info_from_trace = (\n",
    "    b3d.chisight.dense.dense_model.make_dense_multiobject_model(\n",
    "        renderer, likelihood_func\n",
    "    )\n",
    ")\n",
    "importance_jit = jax.jit(model.importance)\n",
    "\n",
    "likelihood_args = {\n",
    "    \"fx\": renderer.fx,\n",
    "    \"fy\": renderer.fy,\n",
    "    \"cx\": renderer.cx,\n",
    "    \"cy\": renderer.cy,\n",
    "    \"image_width\": Pytree.const(renderer.width),\n",
    "    \"image_height\": Pytree.const(renderer.height),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pose_grid = 11\n",
    "position_search_thr = 0.05\n",
    "\n",
    "# Gridding on translation only.\n",
    "translation_deltas = b3d.Pose.concatenate_poses(\n",
    "    [\n",
    "        jax.vmap(lambda p: b3d.Pose.from_translation(p))(\n",
    "            jnp.stack(\n",
    "                jnp.meshgrid(\n",
    "                    jnp.linspace(-position_search_thr, position_search_thr, num_pose_grid),\n",
    "                    jnp.linspace(-position_search_thr, position_search_thr, num_pose_grid),\n",
    "                    jnp.linspace(-position_search_thr, position_search_thr, num_pose_grid),\n",
    "                ),\n",
    "                axis=-1,\n",
    "            ).reshape(-1, 3)\n",
    "        ),\n",
    "        b3d.Pose.identity()[None, ...],\n",
    "    ]\n",
    ")\n",
    "# Sample orientations from a VMF to define a \"grid\" over orientations.\n",
    "rotation_deltas = b3d.Pose.concatenate_poses(\n",
    "    [\n",
    "        jax.vmap(b3d.Pose.sample_gaussian_vmf_pose, in_axes=(0, None, None, None))(\n",
    "            jax.random.split(jax.random.PRNGKey(0), num_pose_grid * num_pose_grid * num_pose_grid),\n",
    "            b3d.Pose.identity(),\n",
    "            0.0001,\n",
    "            10.0,\n",
    "        ),\n",
    "        b3d.Pose.identity()[None, ...],\n",
    "    ]\n",
    ")\n",
    "all_deltas = b3d.Pose.stack_poses([translation_deltas, rotation_deltas])\n",
    "\n",
    "# needs to be odd\n",
    "num_scale_grid = 11\n",
    "scale_search_thr = 0.1\n",
    "\n",
    "scale_deltas = jnp.stack(\n",
    "                jnp.meshgrid(\n",
    "                    jnp.linspace(-scale_search_thr, scale_search_thr, num_scale_grid),\n",
    "                    jnp.linspace(-scale_search_thr, scale_search_thr, num_scale_grid),\n",
    "                    jnp.linspace(-scale_search_thr, scale_search_thr, num_scale_grid),\n",
    "                ),\n",
    "                axis=-1,\n",
    "            ).reshape(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbds = jnp.concatenate([image_arr, jnp.reshape(depth_arr, depth_arr.shape+(1,))], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_T = 0\n",
    "\n",
    "with open(json_file_path) as f:\n",
    "    json_file = json.load(f)\n",
    "pred = json_file['scene'][0]['objects']\n",
    "sample = [0 for _ in range(len(object_ids))]\n",
    "pose_scale_mesh = {}\n",
    "for i, (o_id, idx) in enumerate(zip(object_ids, sample)):\n",
    "    area = mask_util.decode(pred[i]['mask']).astype(bool)\n",
    "    object_colors = jnp.asarray(rgbds[START_T][..., 0:3][area])\n",
    "    mean_object_colors = np.mean(object_colors, axis=0)\n",
    "    pose_scale_mesh[o_id] = b3d.Mesh(ordered_all_meshes[pred[i]['type'][idx]].vertices, ordered_all_meshes[pred[i]['type'][idx]].faces,  jnp.ones(ordered_all_meshes[pred[i]['type'][idx]].vertices.shape)*mean_object_colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/haoliangwang/b3d/saved_traces/test.pickle\", \"rb\") as output_file:\n",
    "    retrieved_tr = msgpack_serialize.load(output_file, model, (Pytree.const([o_id for o_id in object_ids]), [pose_scale_mesh[o_id] for o_id in object_ids], likelihood_args, Pytree.const(True)))\n",
    "viz_trace(retrieved_tr, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.29165232, 0.15955979, 1.7935468 ], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_tr.get_choices()[\"object_scale_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(-6275.1025, dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_tr.get_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: -5862.845703125\n",
      "score: -5862.845703125\n",
      "score: -5862.845703125\n",
      "score: -5862.845703125\n",
      "score: -5862.845703125\n"
     ]
    }
   ],
   "source": [
    "o_id = 0\n",
    "trace = retrieved_tr\n",
    "key = jax.random.PRNGKey(0)\n",
    "for iter in range(5):    \n",
    "    trace, key, _, _ = bayes3d.enumerate_and_select_best_move_pose(\n",
    "        trace, Pytree.const((f\"object_pose_{o_id}\",)), key, all_deltas\n",
    "    )\n",
    "    # trace, key, posterior_scales, scores = bayes3d.enumerate_and_select_best_move_scale(\n",
    "    #     trace, Pytree.const((f\"object_scale_{o_id}\",)), key, scale_deltas\n",
    "    # )\n",
    "    print(f\"score: {trace.get_score()}\")\n",
    "    viz_trace(trace, iter+1, cloud=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pose(position=Array([ 0.91359544, -0.14378065,  0.06828638], dtype=float32), quaternion=Array([ 0.0094165 ,  0.00671392, -0.01218714,  0.99985886], dtype=float32))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace.get_choices()[\"object_pose_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
