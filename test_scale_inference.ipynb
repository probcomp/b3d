{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import trimesh\n",
    "import b3d\n",
    "import genjax\n",
    "import jax\n",
    "import b3d.bayes3d as bayes3d\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import rerun as rr\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "from genjax import Pytree\n",
    "import b3d.chisight.dense.dense_model\n",
    "import b3d.chisight.dense.likelihoods.laplace_likelihood\n",
    "genjax.pretty()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_mesh(vertices, scale_factor):\n",
    "    vertices[:, 0] *= scale_factor[0]\n",
    "    vertices[:, 1] *= scale_factor[1]\n",
    "    vertices[:, 2] *= scale_factor[2]\n",
    "    return vertices\n",
    "\n",
    "def euler_angles_to_quaternion(euler: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert Euler angles to a quaternion.\n",
    "\n",
    "    Source: https://pastebin.com/riRLRvch\n",
    "\n",
    "    :param euler: The Euler angles vector.\n",
    "\n",
    "    :return: The quaternion representation of the Euler angles.\n",
    "    \"\"\"\n",
    "    pitch = np.radians(euler[0] * 0.5)\n",
    "    cp = np.cos(pitch)\n",
    "    sp = np.sin(pitch)\n",
    "\n",
    "    yaw = np.radians(euler[1] * 0.5)\n",
    "    cy = np.cos(yaw)\n",
    "    sy = np.sin(yaw)\n",
    "\n",
    "    roll = np.radians(euler[2] * 0.5)\n",
    "    cr = np.cos(roll)\n",
    "    sr = np.sin(roll)\n",
    "\n",
    "    x = sy * cp * sr + cy * sp * cr\n",
    "    y = sy * cp * cr - cy * sp * sr\n",
    "    z = cy * cp * sr - sy * sp * cr\n",
    "    w = cy * cp * cr + sy * sp * sr\n",
    "    return np.array([x, y, z, w])\n",
    "\n",
    "def get_mask_area(color, seg_img):\n",
    "    arr = seg_img == color\n",
    "    arr = arr.min(-1).astype('float')\n",
    "    arr = arr.reshape((arr.shape[-1], arr.shape[-1]))\n",
    "    return arr.astype(bool)\n",
    "\n",
    "def unproject_pixels(mask, depth_map, cam_matrix, fx, fy, vfov=54.43222, near_plane=0.1, far_plane=100):\n",
    "    '''\n",
    "    pts: [N, 2] pixel coords\n",
    "    depth: [N, ] depth values\n",
    "    returns: [N, 3] world coords\n",
    "    '''\n",
    "    depth = depth_map[mask]\n",
    "    pts = np.array([[x,y] for x,y in zip(np.nonzero(mask)[0], np.nonzero(mask)[1])])\n",
    "    camera_matrix = np.linalg.inv(cam_matrix.reshape((4, 4)))\n",
    "\n",
    "    # Different from real-world camera coordinate system.\n",
    "    # OpenGL uses negative z axis as the camera front direction.\n",
    "    # x axes are same, hence y axis is reversed as well.\n",
    "    # Source: https://learnopengl.com/Getting-started/Camera\n",
    "    rot = np.array([[1, 0, 0, 0],\n",
    "                    [0, -1, 0, 0],\n",
    "                    [0, 0, -1, 0],\n",
    "                    [0, 0, 0, 1]])\n",
    "    camera_matrix = np.dot(camera_matrix, rot)\n",
    "\n",
    "\n",
    "    height = depth_map.shape[0]\n",
    "    width = depth_map.shape[1]\n",
    "\n",
    "    img_pixs = pts[:, [1, 0]].T\n",
    "    img_pix_ones = np.concatenate((img_pixs, np.ones((1, img_pixs.shape[1]))))\n",
    "\n",
    "    # Calculate the intrinsic matrix from vertical_fov.\n",
    "    # Motice that hfov and vfov are different if height != width\n",
    "    # We can also get the intrinsic matrix from opengl's perspective matrix.\n",
    "    # http://kgeorge.github.io/2014/03/08/calculating-opengl-perspective-matrix-from-opencv-intrinsic-matrix\n",
    "    intrinsics = np.array([[fx, 0, width/ 2.0],\n",
    "                           [0, fy, height / 2.0],\n",
    "                           [0, 0, 1]])\n",
    "    img_inv = np.linalg.inv(intrinsics[:3, :3])\n",
    "    cam_img_mat = np.dot(img_inv, img_pix_ones)\n",
    "\n",
    "    points_in_cam = np.multiply(cam_img_mat, depth.reshape(-1))\n",
    "    points_in_cam = np.concatenate((points_in_cam, np.ones((1, points_in_cam.shape[1]))), axis=0)\n",
    "    points_in_world = np.dot(camera_matrix, points_in_cam)\n",
    "    points_in_world = points_in_world[:3, :].T#.reshape(3, height, width)\n",
    "    points_in_cam = points_in_cam[:3, :].T#.reshape(3, height, width)\n",
    "    \n",
    "    return points_in_world\n",
    "\n",
    "def set_axes_equal(ax):\n",
    "    \"\"\"\n",
    "    Make axes of 3D plot have equal scale so that spheres appear as spheres,\n",
    "    cubes as cubes, etc.\n",
    "\n",
    "    Input\n",
    "      ax: a matplotlib axis, e.g., as output from plt.gca().\n",
    "    \"\"\"\n",
    "\n",
    "    x_limits = ax.get_xlim3d()\n",
    "    y_limits = ax.get_ylim3d()\n",
    "    z_limits = ax.get_zlim3d()\n",
    "\n",
    "    x_range = abs(x_limits[1] - x_limits[0])\n",
    "    x_middle = np.mean(x_limits)\n",
    "    y_range = abs(y_limits[1] - y_limits[0])\n",
    "    y_middle = np.mean(y_limits)\n",
    "    z_range = abs(z_limits[1] - z_limits[0])\n",
    "    z_middle = np.mean(z_limits)\n",
    "\n",
    "    # The plot bounding box is a sphere in the sense of the infinity\n",
    "    # norm, hence I call half the max range the plot radius.\n",
    "    plot_radius = 0.5*max([x_range, y_range, z_range])\n",
    "\n",
    "    ax.set_xlim3d([x_middle - plot_radius, x_middle + plot_radius])\n",
    "    ax.set_ylim3d([y_middle - plot_radius, y_middle + plot_radius])\n",
    "    ax.set_zlim3d([z_middle - plot_radius, z_middle + plot_radius])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load basic information from hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths for reading physion metadata\n",
    "physion_assets_path = os.path.join(\n",
    "    b3d.get_root_path(),\n",
    "    \"assets/physion/\",)\n",
    "\n",
    "# stim_name = 'lf_0/dominoes_all_movies/pilot_dominoes_0mid_d3chairs_o1plants_tdwroom_0012'\n",
    "stim_name = '0012_dominoes'\n",
    "\n",
    "hdf5_file_path = os.path.join(physion_assets_path,\n",
    "    f\"{stim_name}.hdf5\",\n",
    ")\n",
    "\n",
    "mesh_file_path = os.path.join(physion_assets_path,\n",
    "    f\"all_flex_meshes/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vfov = 54.43222 \n",
    "near_plane = 0.1\n",
    "far_plane = 100\n",
    "depth_arr = []\n",
    "image_arr = []\n",
    "with h5py.File(hdf5_file_path, \"r\") as f:\n",
    "    # extract depth info\n",
    "    for key in f['frames'].keys():\n",
    "        depth = jnp.flip(jnp.array(f['frames'][key]['images']['_depth_cam0']), 0)\n",
    "        depth_arr.append(depth)\n",
    "        image = jnp.array(Image.open(io.BytesIO(f['frames'][key]['images']['_img_cam0'][:])))\n",
    "        image_arr.append(image)\n",
    "    depth_arr = jnp.asarray(depth_arr)\n",
    "    image_arr = jnp.asarray(image_arr)/255\n",
    "    FINAL_T, height, width = image_arr.shape[0], image_arr.shape[1], image_arr.shape[2]\n",
    "\n",
    "    # extract camera info\n",
    "    camera_azimuth = np.array(f['azimuth']['cam_0'])\n",
    "    camera_matrix = np.array(f['frames']['0000']['camera_matrices']['camera_matrix_cam0']).reshape((4, 4))\n",
    "    projection_matrix = np.array(f['frames']['0000']['camera_matrices']['projection_matrix_cam0']).reshape((4, 4))\n",
    "    im_seg = np.array(Image.open(io.BytesIO(f['frames']['0000']['images']['_id_cam0'][:])))\n",
    "\n",
    "    vfov = vfov / 180.0 * np.pi\n",
    "    tan_half_vfov = np.tan(vfov / 2.0)\n",
    "    tan_half_hfov = tan_half_vfov * width / float(height)\n",
    "    fx = width / 2.0 / tan_half_hfov  # focal length in pixel space\n",
    "    fy = height / 2.0 / tan_half_vfov\n",
    "\n",
    "    # extract object info\n",
    "    object_ids = np.array(f['static']['object_ids'])\n",
    "    model_names = np.array(f['static']['model_names'])\n",
    "    assert len(object_ids) == len(model_names)\n",
    "    object_segmentation_colors = np.array(f['static']['object_segmentation_colors'])\n",
    "    initial_position = np.array(f['static']['initial_position'])\n",
    "    initial_rotation = np.array(f['static']['initial_rotation'])\n",
    "    scales = jnp.array(f['static']['scale'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5       0.01      2.       ]\n",
      " [0.1       0.5       0.25     ]\n",
      " [0.1       0.4793447 0.2752273]\n",
      " [1.        1.        1.       ]\n",
      " [2.3146927 2.3146927 2.3146927]]\n"
     ]
    }
   ],
   "source": [
    "print(scales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b3d modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = np.unique(im_seg.reshape(-1, im_seg.shape[2]), axis=0)\n",
    "num_obj = counter.shape[0]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt pose:  Pose(position=Array([ 0.822018  , -0.00130544,  0.14797577], dtype=float32), quaternion=Array([0., 0., 0., 1.], dtype=float32))\n",
      "[0.502324   0.01942078 1.9540823 ]\n",
      "gt pose:  Pose(position=Array([0.22153097, 0.00367262, 0.04475251], dtype=float32), quaternion=Array([0., 0., 0., 1.], dtype=float32))\n",
      "[0.09917077 0.4963319  0.2503813 ]\n",
      "gt pose:  Pose(position=Array([-0.26237217,  0.00546881,  0.05308981], dtype=float32), quaternion=Array([0., 0., 0., 1.], dtype=float32))\n",
      "[0.15172005 0.4762464  0.28268576]\n",
      "gt pose:  Pose(position=Array([ 0.3589782 ,  0.00375812, -0.98337734], dtype=float32), quaternion=Array([0., 0., 0., 1.], dtype=float32))\n",
      "[0.9909255  0.94450396 0.9329673 ]\n",
      "gt pose:  Pose(position=Array([-0.53901845,  0.05706469,  0.97013205], dtype=float32), quaternion=Array([0., 0., 0., 1.], dtype=float32))\n",
      "[2.1415155 2.1600735 1.9355137]\n"
     ]
    }
   ],
   "source": [
    "# skipping the object id inference step, assuming that we already know which segment mask corresponds to which mesh\n",
    "START_T = 0\n",
    "pose_mesh_color_scale_from_point_cloud = []\n",
    "for (model_name, color, scale) in zip(model_names, object_segmentation_colors, scales):\n",
    "    area = get_mask_area(im_seg, color)\n",
    "    point_cloud = jnp.asarray(unproject_pixels(area, depth_arr[START_T], camera_matrix, fx, fy))\n",
    "    point_cloud_centroid = point_cloud.mean(0)\n",
    "    point_cloud_bottom = min(point_cloud[:,1])\n",
    "    object_pose = b3d.Pose.from_translation(jnp.array([point_cloud_centroid[0], point_cloud_bottom, point_cloud_centroid[2]]))\n",
    "    print(\"gt pose: \", object_pose)\n",
    "    object_colors = jnp.asarray(image_arr[START_T][area])\n",
    "    mean_object_colors = np.mean(object_colors, axis=0)\n",
    "    trim = trimesh.load(os.path.join(mesh_file_path, f\"{model_name.decode('UTF-8')}.obj\"))\n",
    "    bounding_box = trim.bounding_box\n",
    "    bbox_corners = bounding_box.vertices\n",
    "    original_size = jnp.array((max(bbox_corners[:,0])-min(bbox_corners[:,0]), max(bbox_corners[:,1])-min(bbox_corners[:,1]), max(bbox_corners[:,2])-min(bbox_corners[:,2])))\n",
    "    point_cloud_size = jnp.array((max(point_cloud[:,0])-min(point_cloud[:,0]), max(point_cloud[:,1])-min(point_cloud[:,1]), max(point_cloud[:,2])-min(point_cloud[:,2])))\n",
    "    object_scale = (point_cloud_size/original_size)\n",
    "    mesh_info = (scale_mesh(trim.vertices, object_scale), trim.faces, jnp.ones(trim.vertices.shape)*mean_object_colors)\n",
    "    # mesh_info = (scale_mesh(trim.vertices, scale), trim.faces, jnp.ones(trim.vertices.shape)*mean_object_colors)\n",
    "    print(object_scale)\n",
    "    pose_mesh_color_scale_from_point_cloud.append((object_pose, mesh_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "\n",
    "# for idx, (_, mesh) in enumerate(pose_mesh_color_scale_from_point_cloud):\n",
    "#       fig = plt.figure()\n",
    "#       ax = fig.add_subplot(projection='3d')\n",
    "#       ax.set_box_aspect([1,1,1])\n",
    "#       ax.plot_trisurf(mesh[0][:, 0], mesh[0][:,2], mesh[0][:,1], triangles=mesh[1], color=np.mean(mesh[2], axis=0).tolist())\n",
    "#       ax.set_title(idx)\n",
    "#       set_axes_equal(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_object_poses_gt = []\n",
    "# for idx in range(len(object_ids)):\n",
    "#     object_pose = b3d.Pose(jnp.asarray(initial_position[idx]), jnp.asarray(euler_angles_to_quaternion(initial_rotation[idx])))\n",
    "#     all_object_poses_gt.append(object_pose)\n",
    "# all_object_poses_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 objects in library\n"
     ]
    }
   ],
   "source": [
    "object_library = []\n",
    "for (_, obj) in pose_mesh_color_scale_from_point_cloud:\n",
    "    object_library.append(b3d.Mesh(obj[0], obj[1], obj[2]))\n",
    "\n",
    "print(f\"{len(object_library)} objects in library\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = camera_matrix[:3,:3]\n",
    "T = camera_matrix[0:3, 3]\n",
    "a = np.array([-R[0,:], -R[1,:], -R[2,:]])\n",
    "b = np.array(T)\n",
    "camera_position_from_matrix = np.linalg.solve(a, b)\n",
    "camera_rotation_from_matrix = -np.transpose(R)\n",
    "camera_pose = b3d.Pose(\n",
    "    camera_position_from_matrix,\n",
    "    b3d.Rot.from_matrix(camera_rotation_from_matrix).as_quat()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hlwang_ipe_genjax/b3d/.pixi/envs/gpu/lib/python3.12/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Defines the enumeration schedule.\n",
    "scaling_factor = 1.0\n",
    "renderer = b3d.renderer.renderer_original.RendererOriginal(\n",
    "    width * scaling_factor,\n",
    "    height * scaling_factor,\n",
    "    fx * scaling_factor,\n",
    "    fy * scaling_factor,\n",
    "    (width/2) * scaling_factor,\n",
    "    (height/2) * scaling_factor,\n",
    "    near_plane,\n",
    "    far_plane,\n",
    ")\n",
    "\n",
    "b3d.reload(b3d.chisight.dense.dense_model)\n",
    "b3d.reload(b3d.chisight.dense.likelihoods.laplace_likelihood)\n",
    "likelihood_func = b3d.chisight.dense.likelihoods.laplace_likelihood.likelihood_func\n",
    "model, viz_trace, info_from_trace = (\n",
    "    b3d.chisight.dense.dense_model.make_dense_multiobject_model(\n",
    "        renderer, likelihood_func\n",
    "    )\n",
    ")\n",
    "importance_jit = jax.jit(model.importance)\n",
    "\n",
    "likelihood_args = {\n",
    "    \"fx\": renderer.fx,\n",
    "    \"fy\": renderer.fy,\n",
    "    \"cx\": renderer.cx,\n",
    "    \"cy\": renderer.cy,\n",
    "    \"image_width\": Pytree.const(renderer.width),\n",
    "    \"image_height\": Pytree.const(renderer.height),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gridding on translation only.\n",
    "translation_deltas = b3d.Pose.concatenate_poses(\n",
    "    [\n",
    "        jax.vmap(lambda p: b3d.Pose.from_translation(p))(\n",
    "            jnp.stack(\n",
    "                jnp.meshgrid(\n",
    "                    jnp.linspace(-0.1, 0.1, 6),\n",
    "                    jnp.linspace(-0.1, 0.1, 6),\n",
    "                    jnp.linspace(-0.1, 0.1, 6),\n",
    "                ),\n",
    "                axis=-1,\n",
    "            ).reshape(-1, 3)\n",
    "        ),\n",
    "        b3d.Pose.identity()[None, ...],\n",
    "    ]\n",
    ")\n",
    "# Sample orientations from a VMF to define a \"grid\" over orientations.\n",
    "rotation_deltas = b3d.Pose.concatenate_poses(\n",
    "    [\n",
    "        jax.vmap(b3d.Pose.sample_gaussian_vmf_pose, in_axes=(0, None, None, None))(\n",
    "            jax.random.split(jax.random.PRNGKey(0), 6 * 6 * 6),\n",
    "            b3d.Pose.identity(),\n",
    "            0.0001,\n",
    "            100.0,\n",
    "        ),\n",
    "        b3d.Pose.identity()[None, ...],\n",
    "    ]\n",
    ")\n",
    "all_deltas = b3d.Pose.stack_poses([translation_deltas, rotation_deltas])\n",
    "\n",
    "# Sample scales.\n",
    "# scale_deltas = jnp.stack(\n",
    "#                     jnp.meshgrid(\n",
    "#                         jnp.linspace(0.1, 3, 11),\n",
    "#                         jnp.linspace(0.1, 3, 11),\n",
    "#                         jnp.linspace(0.1, 3, 11),\n",
    "#                     ),\n",
    "#                     axis=-1,\n",
    "#                 ).reshape(-1, 3)\n",
    "scale_deltas = dict(\n",
    "    [(\"x\", jnp.array([[x,1,1] for x in jnp.linspace(0.6, 1.1, 8)]).reshape(-1, 3)), \n",
    "     (\"y\", jnp.array([[1,y,1] for y in jnp.linspace(0.6, 1.1, 8)]).reshape(-1, 3)), \n",
    "     (\"z\", jnp.array([[1,1,z] for z in jnp.linspace(0.6, 1.1, 8)]).reshape(-1, 3))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script> (()=>{ if (customElements.get('treescope-container') === undefined) { class TreescopeContainer extends HTMLElement { constructor() { super(); this.attachShadow({mode: \"open\"}); this.defns = {}; this.state = {}; } } customElements.define(\"treescope-container\", TreescopeContainer); } if (customElements.get('treescope-run-here') === undefined) { class RunHere extends HTMLElement { constructor() { super() } connectedCallback() { const run = child => { const fn = new Function(child.textContent); child.textContent = \"\"; fn.call(this); this.remove(); }; const child = this.querySelector(\"script\"); if (child) { run(child); } else { new MutationObserver(()=>{ run(this.querySelector(\"script\")); }).observe(this, {childList: true}); } } } customElements.define(\"treescope-run-here\", RunHere); } })(); </script> <treescope-container class=\"treescope_out_34dfd7b0e655458da9aefcdfb05cd3c9\" ></treescope-container> <treescope-run-here><script type=\"application/octet-stream\"> const root = ( Array.from(document.getElementsByClassName( \"treescope_out_34dfd7b0e655458da9aefcdfb05cd3c9\")) .filter((elt) => !elt.dataset.setup) )[0]; root.dataset.setup = 1; const msg = document.createElement(\"span\"); msg.style = \"color: #aaaaaa; font-family: monospace; transition: opacity 0.2s; opacity: 0.0;\"; msg.textContent = \"(Loading...)\"; root.state.loadingMsg = msg; root.shadowRoot.appendChild(msg); root.state.chain = new Promise((resolve, reject) => { const observer = new IntersectionObserver((entries) => { for (const entry of entries) { if (entry.isIntersecting) { resolve(); observer.disconnect(); return; } } }, {rootMargin: \"1000px\"}); window.setTimeout(() => { if (root.loadingMsg) { root.loadingMsg.style.opacity = \"1.0\"; } observer.observe(root); }, 0); }); root.state.deferring = false; const _insertNode = (node) => { for (let oldScript of node.querySelectorAll(\"script\")) { let newScript = document.createElement(\"script\"); newScript.type = oldScript.type; newScript.textContent = oldScript.textContent; oldScript.parentNode.replaceChild(newScript, oldScript); } if (root.state.loadingMsg) { root.state.loadingMsg.remove(); root.state.loadingMsg = null; } root.shadowRoot.appendChild(node); }; root.defns.insertContent = ((contentNode, compressed) => { if (compressed) { root.state.deferring = true; } if (root.state.deferring) { root.state.chain = (async () => { await root.state.chain; if (compressed) { const encoded = contentNode.textContent; const blob = new Blob([ Uint8Array.from(atob(encoded), (m) => m.codePointAt(0)) ]); const reader = blob.stream().pipeThrough( new DecompressionStream(\"deflate\") ).pipeThrough( new TextDecoderStream(\"utf-8\") ).getReader(); const parts = []; while (true) { const step = await reader.read(); if (step.done) { break; } parts.push(step.value); } const tpl = document.createElement('template'); tpl.innerHTML = parts.join(\"\"); _insertNode(tpl.content); } else { _insertNode(contentNode.content); } })(); } else { _insertNode(contentNode.content); } }); </script></treescope-run-here><div style=\"display:none\"> <script type=\"application/octet-stream\" >eNrlVk1v4zYQ/SuEFthIxUrx2k7iyLaAXIoeih5aoD20hUFRI4sNTaoklcRb5L93SMlxZMtuigbtofJB1nA4780nuTB2KyBLrAYwTNWw0kpZ8gepleGWK5kSDYJa/gBzUipp45JuuNimZKOkMjVlKH+suIXYf6Sk1igR3NjYm47ttkapVBLFOWX3a60aWcRMCaXTduucdF+5QAW0xwtbpaTkFtWkBWnnpKZFweU6FlDalIxZ5UAkxBXwdYWSz8mVMyMt5cj5ZVv3J37ghudccIvMaWPVi27MpdVcGs5iw79Au9rRfV5ctuFZvIQn1o1ETI0ywzSvLXH+LS9oXQvOqIvYpWIWnPca6OYiC8NomWFAEc9YUkApDVkSW3GTrMF+j9H+ThUQRkmljE38OroGlqxqkM7lO+asuk0//zq08g2VhQBclo0Q8xYhQZo/KCVRGj4qfR+R1xzUTyhySz2x5cwJa9Cl0hsqGSRSPYaRzy8ChEcrJG43LchkHKEdXpLwgHUiQK5tRZZLMnIqZ6lrsI2WGHcCwsCeWNVIx+zQtKl4aR0/r+D+POPvBEKIVSUL9Zho+L0BY+8k3/h0fa3pBsI2JpGzMT8CqhtTtWGcD/i4g1i2bpzx8u0cHIs2kVat16LtypXvHKzW2tlyEhD2E4EHLPAuk46d/07uYeuCHujAEeqUEyaoMd9ic3Z2w+DF5mqDZRjswJ8jjCeWv6/xbHE51AAFfyDe4DLoj4+AWJqjp/C0DEYBURLJoNsS9c6V/bCvoduz8zLAtmsHlp8YK6Y2G5T7UvET5AP1j/PiQIWmUtkwrdQD6GhA33EAraFY1TiFoFKiAP3a8I37dUPQk0gJtxS73m0uUZ3mSF6iVyfGJ1Lqqa1af1G74AZBt7sxeahIMiJoDiJNc8AOhFesmH/mg3jtqIw/u1nZjdTRfI/FpR+guVBu5p7E9AE7Ri6ovjdA15h4ebzbx/pAVFETZt5mNhiHNj+sAnYPRRSRr6I9B7d1eNNOv8fQz/yUXPwyvsrZxX9Jr7/pJMnrf4Gky6MDbrRxCawVnnygB3C5eT9Y3woeKPYdbE7V+Pug7t2z8GSPURJuViXXxq6UXLnyH2itc62UjK9cNw2mivxj+m3GDyk6rzZUr/Gu0tLwDf2cPFYgcboJQWsDxV9Pkb9N6AxCOzs8hleCpxoPuZM678FjCKJztFXYn45DoeifUEn/2CNnLBy6KnsH8bDiW8BO2jm8e+K9Wu7O2T7NoFvkxTJ4Ob1uJkDL/HrGbkdsWlx/nsFtPhvPYFLQ6S29mQV9i/2hf1h7qNwmasFl3XSX3cCnJldPwaCRLou42GYQbw9+M747W6/xh07dIPso7Pw3+pTcaU23pBSK2sk4nH3CYkgS8nFt3d0ErWTDr6OQ9YI9GLbx7eQqv8FJXNLRFMZ5Xo6v2WQ6HdFpmVM6+V+GbddzwVuqsFvs3bqCjJAP5EduGrwoffF3XVLxogCMviT78nd9cYIa3jKzPwH+rDXQ</script> <treescope-run-here><script type=\"application/octet-stream\"> const root = ( Array.from(document.getElementsByClassName( \"treescope_out_34dfd7b0e655458da9aefcdfb05cd3c9\")) .filter((elt) => !elt.dataset['step0']) )[0]; root.dataset['step0'] = 1; root.defns.insertContent( this.parentNode.querySelector('script[type=\"application/octet-stream\"]'), true ); this.parentNode.remove(); </script></treescope-run-here> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"display:none\"> <script type=\"application/octet-stream\" >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</script> <treescope-run-here><script type=\"application/octet-stream\"> const root = ( Array.from(document.getElementsByClassName( \"treescope_out_34dfd7b0e655458da9aefcdfb05cd3c9\")) .filter((elt) => !elt.dataset['step1']) )[0]; root.dataset['step1'] = 1; root.defns.insertContent( this.parentNode.querySelector('script[type=\"application/octet-stream\"]'), true ); this.parentNode.remove(); </script></treescope-run-here> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<treescope-run-here><script type=\"application/octet-stream\"> const root = ( Array.from(document.getElementsByClassName( \"treescope_out_34dfd7b0e655458da9aefcdfb05cd3c9\")) .filter((elt) => !elt.dataset.stolen) )[0]; root.dataset.stolen = 1; this.parentNode.replaceChild(root, this); </script></treescope-run-here>"
      ],
      "text/plain": [
       "<jax.Array float32(8,) ≈0.85 ±0.16 [≥0.6, ≤1.1] nonzero:8\n",
       "  <Arrayviz rendering>\n",
       ">"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.linspace(0.6, 1.1, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbds = jnp.concatenate([jnp.flip(image_arr,2), jnp.reshape(jnp.flip(depth_arr,2), depth_arr.shape+(1,))], axis=-1)\n",
    "# rgbds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=[10, 5])\n",
    "# ax = fig.add_subplot(121)\n",
    "# ax.imshow(rgbds[START_T][..., 0:3])\n",
    "\n",
    "# ax = fig.add_subplot(122)\n",
    "# ax.imshow(rgbds[START_T][..., -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.init(\"demo\")\n",
    "rr.connect(\"127.0.0.1:8812\")\n",
    "# b3d.rr_init(\"demo\")\n",
    "rr.log(\"/\", rr.ViewCoordinates.LEFT_HAND_Y_UP, static=True)  # Set an up-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial trace for timestep 0\n",
    "choice_map = dict([(\"camera_pose\", camera_pose), \n",
    "                   (\"rgbd\", rgbds[START_T]), \n",
    "                   (\"depth_noise_variance\", 0.01),\n",
    "                   (\"color_noise_variance\", 0.15),\n",
    "                   (\"outlier_probability\", 0.1)] + \n",
    "                   [(f\"object_pose_{idx}\", pose_mesh_color_scale_from_point_cloud[idx][0]) for idx in range(num_obj)]\n",
    "                   + [(f\"object_scale_{idx}\", jnp.array([1.0, 1.0, 1.0])) for idx in range(num_obj)]\n",
    "                   )\n",
    "\n",
    "trace, _ = importance_jit(\n",
    "    jax.random.PRNGKey(0),\n",
    "    genjax.ChoiceMap.d(\n",
    "        choice_map\n",
    "    ),\n",
    "    (\n",
    "        {\n",
    "            \"num_objects\": Pytree.const(num_obj),\n",
    "            \"meshes\": object_library,\n",
    "            \"likelihood_args\": likelihood_args,\n",
    "            # \"check_interp\": Pytree.const(False),\n",
    "        },\n",
    "    ),\n",
    ")\n",
    "original_trace = trace\n",
    "viz_trace(trace, 0, cloud=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308452.9\n"
     ]
    }
   ],
   "source": [
    "print(trace.get_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "obj 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313862.9\n",
      "obj 1\n",
      "317074.44\n",
      "obj 2\n",
      "319954.34\n",
      "obj 3\n",
      "324970.94\n",
      "obj 4\n",
      "332562.5\n",
      "1\n",
      "obj 0\n",
      "332562.5\n",
      "obj 1\n",
      "332562.5\n",
      "obj 2\n",
      "332419.22\n",
      "obj 3\n",
      "332363.97\n",
      "obj 4\n",
      "332337.3\n",
      "2\n",
      "obj 0\n",
      "332337.3\n",
      "obj 1\n",
      "332337.3\n",
      "obj 2\n",
      "332288.28\n",
      "obj 3\n",
      "332288.28\n",
      "obj 4\n",
      "332261.66\n",
      "3\n",
      "obj 0\n",
      "332261.66\n",
      "obj 1\n",
      "332261.66\n",
      "obj 2\n",
      "331908.34\n",
      "obj 3\n",
      "331908.34\n",
      "obj 4\n",
      "331908.34\n",
      "4\n",
      "obj 0\n",
      "331908.34\n",
      "obj 1\n",
      "331908.34\n",
      "obj 2\n",
      "332419.88\n",
      "obj 3\n",
      "332419.88\n",
      "obj 4\n",
      "332419.88\n",
      "5\n",
      "obj 0\n",
      "332419.88\n",
      "obj 1\n",
      "332419.88\n",
      "obj 2\n",
      "332282.3\n",
      "obj 3\n",
      "332282.3\n",
      "obj 4\n",
      "332282.3\n",
      "6\n",
      "obj 0\n",
      "332282.3\n",
      "obj 1\n",
      "332282.3\n",
      "obj 2\n",
      "332282.3\n",
      "obj 3\n",
      "332282.3\n",
      "obj 4\n",
      "332282.3\n",
      "7\n",
      "obj 0\n",
      "332282.3\n",
      "obj 1\n",
      "332282.3\n",
      "obj 2\n",
      "332282.3\n",
      "obj 3\n",
      "332282.3\n",
      "obj 4\n",
      "332282.3\n",
      "8\n",
      "obj 0\n",
      "332282.3\n",
      "obj 1\n",
      "332282.3\n",
      "obj 2\n",
      "332282.3\n",
      "obj 3\n",
      "332282.3\n",
      "obj 4\n",
      "332282.3\n",
      "9\n",
      "obj 0\n",
      "332282.3\n",
      "obj 1\n",
      "332282.3\n",
      "obj 2\n",
      "332282.3\n",
      "obj 3\n",
      "332282.3\n",
      "obj 4\n",
      "332282.3\n"
     ]
    }
   ],
   "source": [
    "trace = original_trace\n",
    "num_inference_step = 10\n",
    "for seed in range(num_inference_step):\n",
    "    print(seed)\n",
    "    key = jax.random.PRNGKey(seed)\n",
    "    for idx in range(num_obj):\n",
    "        print(f\"obj {idx}\")\n",
    "        trace, key = bayes3d.enumerate_and_select_best_move(\n",
    "            trace, Pytree.const((f\"object_pose_{idx}\", f\"object_scale_{idx}\",)), key, [all_deltas, scale_deltas['x']]\n",
    "            # trace, Pytree.const((f\"object_pose_{idx}\",)), key, [all_deltas]\n",
    "        )\n",
    "        trace, key = bayes3d.enumerate_and_select_best_move(\n",
    "            trace, Pytree.const((f\"object_pose_{idx}\", f\"object_scale_{idx}\",)), key, [all_deltas, scale_deltas['y']]\n",
    "        )\n",
    "        trace, key = bayes3d.enumerate_and_select_best_move(\n",
    "            trace, Pytree.const((f\"object_pose_{idx}\", f\"object_scale_{idx}\",)), key, [all_deltas, scale_deltas['z']]\n",
    "        )\n",
    "        print(trace.get_score())\n",
    "    viz_trace(trace, seed+1, cloud=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.  1.  1.1]\n",
      "[1.  1.  1.1]\n",
      "[1.        1.        1.0285714]\n",
      "[1.  1.  1.1]\n",
      "[1.  1.  1.1]\n"
     ]
    }
   ],
   "source": [
    "for idx in range(num_obj):\n",
    "    addr = f\"object_scale_{idx}\"\n",
    "    current_scale = trace.get_choices()[addr]\n",
    "    print(current_scale) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_scale = jnp.array([0.1,0.1,0.1])\n",
    "new_trace = trace.update(\n",
    "        jax.random.PRNGKey(0),\n",
    "        genjax.ChoiceMap.d({'object_scale_3': new_scale,}),\n",
    "    )[0]\n",
    "viz_trace(new_trace, START_T, cloud=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325487.47\n"
     ]
    }
   ],
   "source": [
    "print(new_trace.get_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_trace(new_trace, START_T, cloud=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_trace(trace, START_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [15:56<00:00,  3.81s/it]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-09-16T03:16:32Z WARN  re_sdk_comms::buffered_client] Failed to send message after 3 attempts: Failed to send to Rerun server at 127.0.0.1:8812: Connection reset by peer (os error 104)\n",
      "[2024-09-16T03:16:34Z WARN  re_sdk_comms::buffered_client] Dropping messages because tcp client has timed out.\n",
      "[2024-09-16T03:16:34Z WARN  re_sdk_comms::buffered_client] Dropping messages because tcp client has timed out.\n"
     ]
    }
   ],
   "source": [
    "FINAL_T = len(image_arr)\n",
    "for T_observed_image in tqdm(range(FINAL_T)):\n",
    "    # Constrain on new RGB and Depth data.\n",
    "    trace = b3d.update_choices(\n",
    "        trace,\n",
    "        Pytree.const((\"rgbd\",)),\n",
    "        rgbds[T_observed_image],\n",
    "    )\n",
    " \n",
    "    for idx in range(num_obj):\n",
    "        trace, key = bayes3d.enumerate_and_select_best_move(\n",
    "            trace, Pytree.const((f\"object_pose_{idx}\", f\"object_scale_{idx}\",)), key, [all_deltas, scale_deltas['x']]\n",
    "        )\n",
    "        trace, key = bayes3d.enumerate_and_select_best_move(\n",
    "            trace, Pytree.const((f\"object_pose_{idx}\", f\"object_scale_{idx}\",)), key, [all_deltas, scale_deltas['y']]\n",
    "        )\n",
    "        trace, key = bayes3d.enumerate_and_select_best_move(\n",
    "            trace, Pytree.const((f\"object_pose_{idx}\", f\"object_scale_{idx}\",)), key, [all_deltas, scale_deltas['z']]\n",
    "        )\n",
    "    viz_trace(trace, T_observed_image+num_inference_step, cloud=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
