{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 18:19:44.174227: W external/xla/xla/service/gpu/nvptx_compiler.cc:718] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.4.131). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import trimesh\n",
    "import b3d\n",
    "from jax.scipy.spatial.transform import Rotation as Rot\n",
    "from b3d import Pose\n",
    "import rerun as rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.init(\"demo.py\")\n",
    "rr.connect(\"127.0.0.1:8812\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "width=100\n",
    "height=100\n",
    "fx=50.0\n",
    "fy=50.0\n",
    "cx=50.0\n",
    "cy=50.0\n",
    "near=0.001\n",
    "far=16.0\n",
    "renderer = b3d.Renderer(\n",
    "    width, height, fx, fy, cx, cy, near, far\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Render color\n",
    "from pathlib import Path\n",
    "mesh_path = Path(b3d.__file__).parents[1] / \"assets/006_mustard_bottle/textured_simple.obj\"\n",
    "mesh = trimesh.load(mesh_path)\n",
    "\n",
    "vertices = jnp.array(mesh.vertices) * 20.0\n",
    "vertices = vertices - vertices.mean(0)\n",
    "faces = jnp.array(mesh.faces)\n",
    "vertex_colors = jnp.array(mesh.visual.to_color().vertex_colors)[...,:3] / 255.0\n",
    "ranges = jnp.array([[0, len(faces)]])\n",
    "\n",
    "pose = Pose.from_position_and_target(\n",
    "    jnp.array([3.2, 0.5, 0.0]),\n",
    "    jnp.array([0.0, 0.0, 0.0])\n",
    "\n",
    ").inverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.log(\n",
    "    \"/3d/mesh\",\n",
    "    rr.Mesh3D(\n",
    "        vertex_positions=vertices,\n",
    "        indices=faces,\n",
    "        vertex_colors=vertex_colors\n",
    "    ),\n",
    "    timeless=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "num_frames = 60\n",
    "\n",
    "poses = [\n",
    "    Pose.sample_gaussian_vmf_pose(\n",
    "        jax.random.PRNGKey(15),\n",
    "        Pose.from_translation(jnp.array([-2.0, 0.3, 3.5])),\n",
    "        0.01, 10.0\n",
    "    )\n",
    "]\n",
    "delta_pose = Pose(\n",
    "    jnp.array([0.09, 0.05, 0.02]),\n",
    "    Rot.from_euler(\"zyx\", [-1.0, 0.1, 2.0], degrees=True).as_quat()\n",
    ")\n",
    "for t in range(num_frames - 1):\n",
    "    poses.append(poses[-1] @ delta_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frames:  (60,)\n"
     ]
    }
   ],
   "source": [
    "all_gt_poses = Pose.stack_poses(poses)\n",
    "print(\"Number of frames: \", all_gt_poses.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "_,_,_,observed_images = renderer.render_many(\n",
    "    all_gt_poses.as_matrix()[:,None,...], vertices, faces, ranges)\n",
    "for t in range(num_frames):\n",
    "    rr.set_time_sequence(\"frame\", t)\n",
    "    rr.log(\"observed_image\", rr.DepthImage((observed_images[t,...])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "translation_deltas = jax.vmap(lambda p: Pose.from_translation(p))(jnp.stack(\n",
    "    jnp.meshgrid(\n",
    "        jnp.linspace(-0.2, 0.2, 5),\n",
    "        jnp.linspace(-0.2, 0.2, 5),\n",
    "        jnp.linspace(-0.2, 0.2, 5),\n",
    "    ),\n",
    "    axis=-1,\n",
    ").reshape(-1, 3))\n",
    "\n",
    "rotation_deltas = jax.vmap(Pose.sample_gaussian_vmf_pose, in_axes=(0,None, None, None))(\n",
    "    jax.random.split(jax.random.PRNGKey(0), 200),\n",
    "    Pose.identity(),\n",
    "    0.001, 100.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def likelihood_fn(observed_depth, rendered_depth):\n",
    "    return (jnp.abs(observed_depth - rendered_depth) < 0.1).sum()\n",
    "likelihood_fn_parallel = jax.vmap(likelihood_fn, in_axes=(None,0))\n",
    "\n",
    "def update_pose_estimate(pose_estimate, gt_depth):\n",
    "    proposals = pose_estimate @ translation_deltas\n",
    "    rendered_depth = renderer.render_many(\n",
    "        proposals.as_matrix()[:,None,...], vertices, faces, ranges\n",
    "    )[3]\n",
    "    weights_new = likelihood_fn_parallel(gt_depth, rendered_depth)\n",
    "    pose_estimate = proposals[jnp.argmax(weights_new)]\n",
    "\n",
    "    proposals = pose_estimate @ rotation_deltas\n",
    "    rendered_depth = renderer.render_many(\n",
    "        proposals.as_matrix()[:,None,...], vertices, faces, ranges\n",
    "    )[3]\n",
    "    weights_new = likelihood_fn_parallel(gt_depth, rendered_depth)\n",
    "    pose_estimate = proposals[jnp.argmax(weights_new)]\n",
    "    return pose_estimate, pose_estimate\n",
    "\n",
    "inference_program = jax.jit(lambda p, x: jax.lax.scan(update_pose_estimate, p, x)[1])\n",
    "inferred_poses = inference_program(all_gt_poses[0], observed_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0.3366236686706543\n",
      "FPS: 178.24058610300148\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "pose_estimates_over_time = inference_program(poses[0], observed_images)\n",
    "end = time.time()\n",
    "print(\"Time elapsed:\", end - start)\n",
    "print(\"FPS:\", all_gt_poses.shape[0] / (end - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inferred_images = renderer.render_many(pose_estimates_over_time.as_matrix()[:,None,...], vertices, faces, ranges)[3]\n",
    "for t in range(num_frames):\n",
    "    rr.set_time_sequence(\"frame\", t)\n",
    "    rr.log(\"observed_image/inferred\", rr.DepthImage(inferred_images[t,...]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pose = Pose.from_position_and_target(\n",
    "    jnp.array([3.2, 0.5, 0.0]),\n",
    "    jnp.array([0.0, 0.0, 0.0])\n",
    "\n",
    ").inverse()\n",
    "image, depth = renderer.render_attribute(pose.as_matrix()[None,...], vertices, faces, ranges, vertex_colors)\n",
    "rr.log(\"rgb_image\", rr.Image(image), timeless=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "b3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
