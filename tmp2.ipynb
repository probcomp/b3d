{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-09 01:04:11.823466: W external/xla/xla/service/gpu/nvptx_compiler.cc:718] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.4.131). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "import rerun as rr\n",
    "import genjax\n",
    "import os\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "from b3d import Pose\n",
    "import b3d\n",
    "from tqdm   import tqdm\n",
    "\n",
    "PORT = 8812\n",
    "rr.init(\"online_learning\")\n",
    "rr.connect(addr=f'127.0.0.1:{PORT}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = os.path.join(b3d.get_assets_path(),\n",
    "#  \"shared_data_bucket/input_data/orange_mug_pan_around_and_pickup.r3d.video_input.npz\")\n",
    "# \"shared_data_bucket/input_data/shout_on_desk.r3d.video_input.npz\")\n",
    "\"shared_data_bucket/input_data/desk_ramen2_spray1.r3d.video_input.npz\")\n",
    "video_input = b3d.VideoInput.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_library = b3d.MeshLibrary.make_empty_library()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width, image_height, fx,fy, cx,cy,near,far = np.array(video_input.camera_intrinsics_depth)\n",
    "image_width, image_height = int(image_width), int(image_height)\n",
    "fx,fy, cx,cy,near,far = float(fx),float(fy), float(cx),float(cy),float(near),float(far)\n",
    "\n",
    "rgbs = video_input.rgb[::3] / 255.0\n",
    "xyzs = video_input.xyz[::3]\n",
    "# Resize rgbs to be same size as depth.\n",
    "rgbs_resized = jnp.clip(jax.vmap(jax.image.resize, in_axes=(0, None, None))(\n",
    "    rgbs, (video_input.xyz.shape[1], video_input.xyz.shape[2], 3), \"linear\"\n",
    "), 0.0, 1.0)\n",
    "\n",
    "point_cloud_og = xyzs[0].reshape(-1,3)\n",
    "colors_og = rgbs_resized[0].reshape(-1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub = jax.random.choice(jax.random.PRNGKey(0), jnp.arange(len(point_cloud)), (len(point_cloud)//6,), replace=False)\n",
    "DIV = 20\n",
    "sub = jnp.linspace(0, point_cloud_og.shape[0], num=point_cloud_og.shape[0]//DIV, dtype=int)\n",
    "point_cloud = point_cloud_og[sub]\n",
    "colors = colors_og[sub]\n",
    "vertices, faces, vertex_colors, face_colors = b3d.make_mesh_from_point_cloud_and_resolution(\n",
    "    point_cloud, colors, point_cloud[:,2] / fx * 2.0 * jnp.sqrt(DIV) * 1.25\n",
    ")\n",
    "# object_pose = Pose.from_translation(vertices.mean(0))\n",
    "# vertices = object_pose.inverse().apply(vertices)\n",
    "object_library.add_object(vertices, faces, vertex_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.log(\n",
    "    \"/3d/mesh\",\n",
    "    rr.Mesh3D(\n",
    "        vertex_positions=vertices,\n",
    "        indices=faces,\n",
    "        vertex_colors=vertex_colors\n",
    "    ),\n",
    "    timeless=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renderer = b3d.Renderer(image_width, image_height, fx, fy, cx, cy, near, far)\n",
    "model = b3d.model_multiobject_gl_factory(renderer)\n",
    "\n",
    "color_error, depth_error = (jnp.float32(30.0), jnp.float32(0.02))\n",
    "inlier_score, outlier_prob = (jnp.float32(5.0), jnp.float32(0.001))\n",
    "color_multiplier, depth_multiplier = (jnp.float32(3000.0), jnp.float32(3000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "translation_deltas = Pose.concatenate_poses([jax.vmap(lambda p: Pose.from_translation(p))(jnp.stack(\n",
    "    jnp.meshgrid(\n",
    "        jnp.linspace(-0.01, 0.01, 11),\n",
    "        jnp.linspace(-0.01, 0.01, 11),\n",
    "        jnp.linspace(-0.01, 0.01, 11),\n",
    "    ),\n",
    "    axis=-1,\n",
    ").reshape(-1, 3)), Pose.identity()[None,...]])\n",
    "\n",
    "rotation_deltas = Pose.concatenate_poses([jax.vmap(Pose.sample_gaussian_vmf_pose, in_axes=(0,None, None, None))(\n",
    "    jax.random.split(jax.random.PRNGKey(0), 11*11*11),\n",
    "    Pose.identity(),\n",
    "    0.00001, 1000.0\n",
    "), Pose.identity()[None,...]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_deltas =  Pose.stack_poses([translation_deltas, rotation_deltas])\n",
    "\n",
    "from functools import partial\n",
    "@partial(jax.jit, static_argnames=['addressses'])\n",
    "def enumerative_proposal(trace, addressses, key, all_deltas):\n",
    "    addr = addressses.const[0]\n",
    "    current_pose = trace[addr]\n",
    "    for i in range(len(all_deltas)):\n",
    "        test_poses = current_pose @ all_deltas[i]\n",
    "        potential_scores = b3d.enumerate_choices_get_scores(\n",
    "            trace, jax.random.PRNGKey(0), addressses, test_poses\n",
    "        )\n",
    "        current_pose = test_poses[potential_scores.argmax()]\n",
    "    trace = b3d.update_choices(\n",
    "        trace, key, addressses, current_pose\n",
    "    )\n",
    "    return trace, key\n",
    "\n",
    "\n",
    "REAQUISITION_TS = [0, 95,222,355, len(rgbs_resized)]\n",
    "\n",
    "importance_jit = jax.jit(model.importance)\n",
    "update_jit = jax.jit(model.update)\n",
    "\n",
    "START_T = 0\n",
    "trace, _ = importance_jit(\n",
    "    jax.random.PRNGKey(0),\n",
    "    genjax.choice_map(\n",
    "        dict([\n",
    "            (\"camera_pose\", Pose.identity()),\n",
    "            (\"object_pose_0\", Pose.identity()),\n",
    "            (\"object_0\", 0),\n",
    "            (\"object_1\", -1),\n",
    "            (\"object_2\", -1),\n",
    "            (\"object_3\", -1),\n",
    "            (\"observed_rgb\", rgbs_resized[START_T]),\n",
    "            (\"observed_depth\", xyzs[START_T,...,2]),\n",
    "        ])\n",
    "    ),\n",
    "    (jnp.arange(4),color_error,depth_error,inlier_score,outlier_prob,color_multiplier,depth_multiplier, object_library)\n",
    ")\n",
    "b3d.rerun_visualize_trace_t(trace, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [01:07<00:00,  1.41it/s]\n",
      "100%|██████████| 127/127 [02:40<00:00,  1.26s/it]\n",
      "100%|██████████| 133/133 [04:08<00:00,  1.87s/it]\n",
      "100%|██████████| 72/72 [03:12<00:00,  2.68s/it]\n"
     ]
    }
   ],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "\n",
    "inference_data_over_time = []\n",
    "for reaquisition_phase in range(len(REAQUISITION_TS)-1):\n",
    "    for T_observed_image in tqdm(range(REAQUISITION_TS[reaquisition_phase], REAQUISITION_TS[reaquisition_phase+1])):\n",
    "        trace = b3d.update_choices_jit(trace, key,\n",
    "            genjax.Pytree.const([\"observed_rgb\", \"observed_depth\"]),\n",
    "            rgbs_resized[T_observed_image],\n",
    "            xyzs[T_observed_image,...,2]\n",
    "        )\n",
    "        trace,key = enumerative_proposal(trace, genjax.Pytree.const([\"camera_pose\"]), key, all_deltas)\n",
    "        for i in range(1, len(object_library.ranges)):\n",
    "            trace,key = enumerative_proposal(trace, genjax.Pytree.const([f\"object_pose_{i}\"]), key, all_deltas)\n",
    "        b3d.rerun_visualize_trace_t(trace, T_observed_image)\n",
    "        inference_data_over_time.append((b3d.get_poses_from_trace(trace),b3d.get_object_ids_from_trace(trace), trace[\"camera_pose\"], T_observed_image ))\n",
    "\n",
    "    rgb_inliers, rgb_outliers = b3d.get_rgb_inlier_outlier_from_trace(trace)\n",
    "    depth_inliers, depth_outliers = b3d.get_depth_inlier_outlier_from_trace(trace)\n",
    "    rr.set_time_sequence(\"frame\", T_observed_image)\n",
    "    rr.log(\"/rgb/rgb_outliers\", rr.Image(jnp.tile((rgb_outliers*1.0)[...,None], (1,1,3))))\n",
    "    rr.log(\"/rgb/depth_outliers\", rr.Image(jnp.tile((depth_outliers*1.0)[...,None], (1,1,3))))\n",
    "\n",
    "    outler_mask = jnp.logical_and(rgb_outliers , depth_outliers)\n",
    "    rr.log(\"outliers\", rr.Image(jnp.tile((outler_mask*1.0)[...,None], (1,1,3))))\n",
    "\n",
    "    point_cloud = b3d.xyz_from_depth(trace[\"observed_depth\"], fx,fy,cx,cy)[outler_mask]\n",
    "    point_cloud_colors = trace[\"observed_rgb\"][outler_mask]\n",
    "\n",
    "    assignment = b3d.segment_point_cloud(point_cloud)\n",
    "\n",
    "    point_cloud = point_cloud.reshape(-1,3)[assignment==0]\n",
    "    point_cloud_colors = point_cloud_colors.reshape(-1,3)[assignment==0]\n",
    "    \n",
    "    sub = jax.random.choice(jax.random.PRNGKey(0), jnp.arange(len(point_cloud)), (len(point_cloud)//4,), replace=False)\n",
    "    point_cloud = point_cloud[sub]\n",
    "    colors = point_cloud_colors[sub]\n",
    "\n",
    "    vertices, faces, vertex_colors, face_colors = b3d.make_mesh_from_point_cloud_and_resolution(\n",
    "        point_cloud, colors, point_cloud[:,2] / fx * 2.0\n",
    "    )\n",
    "\n",
    "    object_pose = Pose.from_translation(vertices.mean(0))\n",
    "    vertices = object_pose.inverse().apply(vertices)\n",
    "    object_library.add_object(vertices, faces, vertex_colors)\n",
    "\n",
    "    REAQUISITION_T = REAQUISITION_TS[reaquisition_phase+1]-1\n",
    "    next_object_id = len(object_library.ranges)-1\n",
    "    trace = trace.update(\n",
    "        key,\n",
    "        genjax.choice_map({f\"object_{next_object_id}\": next_object_id, f\"object_pose_{next_object_id}\": trace[\"camera_pose\"] @ object_pose, \"observed_rgb\": rgbs_resized[REAQUISITION_T], \"observed_depth\": xyzs[REAQUISITION_T,...,2] }),\n",
    "        # genjax.Diff.tree_diff_unknown_change((jnp.arange(2), *trace.get_args()[1:]))\n",
    "        genjax.Diff.tree_diff_unknown_change((jnp.arange(4),color_error,depth_error,inlier_score,outlier_prob,color_multiplier,depth_multiplier, object_library))\n",
    "    )[0]\n",
    "    b3d.rerun_visualize_trace_t(trace, REAQUISITION_T)\n",
    "    inference_data_over_time.append((b3d.get_poses_from_trace(trace),b3d.get_object_ids_from_trace(trace), trace[\"camera_pose\"], T_observed_image ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 431/431 [00:40<00:00, 10.55it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(inference_data_over_time))):\n",
    "    poses, object_ids, camera_pose, t = inference_data_over_time[i]\n",
    "    trace = update_jit(\n",
    "        key,\n",
    "        trace,\n",
    "        genjax.choice_map(\n",
    "            dict([\n",
    "                *[(f\"object_pose_{i}\", poses[i]) for i in range(len(poses))],\n",
    "                *[(f\"object_{i}\", object_ids[i])for i in range(len(object_ids))],\n",
    "                (\"camera_pose\", camera_pose),\n",
    "                (\"observed_rgb\", rgbs_resized[t]),\n",
    "                (\"observed_depth\", xyzs[t,...,2]),\n",
    "            ])\n",
    "        ),\n",
    "        genjax.Diff.tree_diff_unknown_change((jnp.arange(4),color_error,depth_error,inlier_score,outlier_prob,color_multiplier,depth_multiplier, object_library))\n",
    "    )[0]\n",
    "    b3d.rerun_visualize_trace_t(trace, t)\n",
    "    rr.set_time_sequence(\"frame\", t)\n",
    "    outler_mask = jnp.logical_and(rgb_outliers , depth_outliers)\n",
    "\n",
    "    rgb_inliers, rgb_outliers = b3d.get_rgb_inlier_outlier_from_trace(trace)\n",
    "    depth_inliers, depth_outliers = b3d.get_depth_inlier_outlier_from_trace(trace)\n",
    "\n",
    "    rr.log(\"outliers\", rr.Image(jnp.tile((outler_mask*1.0)[...,None], (1,1,3))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "b3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
